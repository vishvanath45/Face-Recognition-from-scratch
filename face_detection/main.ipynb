{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precog Project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  I have a folder in which named TEST_dataset, which has 3 sub folder named namo, ak , and people \n",
    "#  containing 50 images in each of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from skimage import io\n",
    "# import dlib\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We now want to convert the entire dataset into a 3D array\n",
    "# (image index, x, y), with mean = 0  and s.d. = 0.5\n",
    "#  give 3 diff folderpaths namo, ak, people\n",
    "img_wd = 200 #it is known\n",
    "img_ht = 200 #it is known\n",
    "\n",
    "def load_pictures(folderpath):\n",
    "    '''Loading for a single image'''\n",
    "    img_files = os.listdir(folderpath)\n",
    "    tot_imgs = len(img_files)\n",
    "    \n",
    "#     print img_files[1]\n",
    "#     full_path = os.path.join(folderpath,img_files[1])\n",
    "#     img_data = (ndimage.imread(full_path).astype(float) - 255.0/2)/255.0\n",
    "#     for converting (200,200,3)\n",
    "#     img_data = img_data[:,:,0]\n",
    "#     print img_data.shape\n",
    "#     print img_data\n",
    "#     new_arr = img_data.reshape(120000)\n",
    "#     print new_arr\n",
    "    \n",
    "    dataset = np.ndarray(shape = (tot_imgs, img_wd*img_ht*3),\n",
    "                         dtype = np.float32)\n",
    "    img_index = 0\n",
    "    for img in img_files:\n",
    "        img_file_path = os.path.join(folderpath, img)\n",
    "        try:\n",
    "            img_data = (ndimage.imread(img_file_path).astype(float) - 255.0/2)/255.0\n",
    "#             # We did the above to set the range of the image data to \n",
    "#             # -0.5 to 0.5 (s.d.)\n",
    "            img_data = img_data.reshape(img_wd*img_ht*3)\n",
    "            dataset[img_index, :] = img_data\n",
    "            img_index = img_index + 1\n",
    "        except IOError as e:\n",
    "            print('file read error, skipping thsi file')\n",
    "                \n",
    "    print('Full dataset shape', dataset.shape)\n",
    "    print('Dataset Mean', np.mean(dataset))\n",
    "    print('Dataset SD', np.std(dataset))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sharma/.local/lib/python2.7/site-packages/ipykernel_launcher.py:28: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Full dataset shape', (400, 120000))\n",
      "('Dataset Mean', -0.065289788)\n",
      "('Dataset SD', 0.2462582)\n",
      "('Full dataset shape', (400, 120000))\n",
      "('Dataset Mean', 0.0063913679)\n",
      "('Dataset SD', 0.22900349)\n",
      "('Full dataset shape', (400, 120000))\n",
      "('Dataset Mean', -0.030012263)\n",
      "('Dataset SD', 0.26703113)\n"
     ]
    }
   ],
   "source": [
    "data_set_ak = load_pictures(\"./TEST_dataset/ak\")\n",
    "data_set_namo = load_pictures(\"./TEST_dataset/namo\")\n",
    "data_set_people = load_pictures(\"./TEST_dataset/people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now i have created Flattened Image data set for each three \n",
    "# of categories\n",
    "\n",
    "#  one such db can be \n",
    "# [ R,G,B,R,G,B,R,G,B,R,G,B,R,G,B,R,G,B ..... 200*200  ] pixals\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# for all images for a given person\n",
    "# so now size of a given db is (400*20000)\n",
    "#  next task to create a label for each dataset \n",
    "# if 1 represents modi\n",
    "# it should be like\n",
    "# [1]\n",
    "# [1]\n",
    "# [1]\n",
    "# [1]\n",
    "# CONVENTION\n",
    "# 1 --> NAMO\n",
    "# 2 --> AK\n",
    "# 3 --> PEOPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now I have to divide dataset in TRAIN, TEST, CROSS_VALIDATION\n",
    "# total 400 images of each\n",
    "# 50% --> TRAIN (300 imgs in each class)\n",
    "# 25% -->TEST (50 imgs '' )\n",
    "# 25% -->CV (50 imgs '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_train_namo = data_set_namo[0:300]\n",
    "dataset_test_namo = data_set_namo[300:350]\n",
    "dataset_cv_namo = data_set_namo[350:400]\n",
    "\n",
    "dataset_train_ak = data_set_ak[0:300]\n",
    "dataset_test_ak = data_set_ak[300:350]\n",
    "dataset_cv_ak = data_set_ak[350:400]\n",
    "\n",
    "dataset_train_people = data_set_people[0:300]\n",
    "dataset_test_people = data_set_people[300:350]\n",
    "dataset_cv_people = data_set_people[350:400]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 120000)\n",
      "(150, 120000)\n",
      "(150, 120000)\n"
     ]
    }
   ],
   "source": [
    "dataset_train_final = np.concatenate((dataset_train_namo,dataset_train_ak))\n",
    "dataset_train_final = np.concatenate((dataset_train_final,dataset_train_people))\n",
    "print dataset_train_final.shape\n",
    "\n",
    "dataset_test_final = np.concatenate((dataset_test_namo,dataset_test_ak))\n",
    "dataset_test_final = np.concatenate((dataset_test_final,dataset_test_people))\n",
    "print dataset_test_final.shape\n",
    "\n",
    "dataset_cv_final = np.concatenate((dataset_cv_namo,dataset_cv_ak))\n",
    "dataset_cv_final = np.concatenate((dataset_cv_final,dataset_cv_people))\n",
    "print dataset_test_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[          1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "           1           1           1           1           1           1\n",
      "  -393027064       21880  -393027088       21880  -393027112       21880\n",
      "  -393027136       21880  -393027160       21880  -393027184       21880\n",
      "  -393027208       21880  -393027232       21880  -393027256       21880\n",
      "  -393027280       21880  -393027304       21880  -393027328       21880\n",
      "  -393027352       21880  -393027376       21880  -393027400       21880\n",
      "  -393027424       21880  -393027448       21880  -393027472       21880\n",
      "  -393027496       21880  -393027520       21880  -393027544       21880\n",
      "  -393027568       21880  -393027592       21880  -393027616       21880\n",
      "  -393027640       21880  -393025672       21880  -393025696       21880\n",
      "  -393025720       21880  -393025744       21880  -393025768       21880\n",
      "  -393025792       21880  -393025816       21880  -393025840       21880\n",
      "  -393025864       21880  -393025888       21880  -393025912       21880\n",
      "  -393025936       21880  -393025960       21880  -393025984       21880\n",
      "  -393026008       21880  -393026032       21880        3889           0\n",
      " -1982911656       32605 -1982911656       32605           0           0\n",
      "           0           0  -393026176       21880  -393026200       21880\n",
      "  -393026224       21880  -393026248       21880  -393026272       21880\n",
      "  -393026296       21880  -393026320       21880  -393026344       21880\n",
      "  -393026368       21880  -393026392       21880  -393026416       21880\n",
      "  -393026440       21880  -393026464       21880  -393026488       21880\n",
      "  -393026512       21880  -393026536       21880  -393026560       21880\n",
      "  -393026584       21880  -393026608       21880  -393026632       21880\n",
      "  -393024664       21880  -393024688       21880  -393024712       21880\n",
      "  -393024736       21880  -393024760       21880  -393024784       21880\n",
      "  -393024808       21880  -393024832       21880  -393024856       21880\n",
      "  -393024880       21880  -393024904       21880  -393024928       21880\n",
      "  -393024952       21880  -393024976       21880  -393025000       21880\n",
      "  -393025024       21880  -393025048       21880  -393025072       21880\n",
      "  -393025096       21880  -393025120       21880  -393025144       21880\n",
      "  -393025168       21880  -393025192       21880  -393025216       21880\n",
      "  -393025240       21880  -393025264       21880  -393025288       21880\n",
      "  -393025312       21880  -393025336       21880  -393025360       21880\n",
      "  -393025384       21880  -393025408       21880  -393025432       21880\n",
      "  -393025456       21880  -393025480       21880  -393025504       21880\n",
      "  -393025528       21880  -393025552       21880  -393025576       21880\n",
      "  -393025600       21880  -393025624       21880  -393023656       21880\n",
      "  -393023680       21880  -393023704       21880  -393023728       21880\n",
      "  -393023752       21880  -393023776       21880  -393023800       21880\n",
      "  -393023824       21880  -393023848       21880  -393023872       21880\n",
      "  -393023896       21880  -393023920       21880  -393023944       21880\n",
      "  -393023968       21880  -393023992       21880  -393024016       21880\n",
      "  -393024040       21880  -393024064       21880  -393024088       21880\n",
      "  -393024112       21880  -393024136       21880  -393024160       21880\n",
      "  -393024184       21880  -393024208       21880  -393024232       21880\n",
      "  -393024256       21880  -393024280       21880  -393024304       21880\n",
      "  -393024328       21880  -393024352       21880  -393024376       21880\n",
      "  -393024400       21880        3105           0 -1982911656       32605\n",
      " -1982911656       32605           0           0           0           0\n",
      "  -393024544       21880  -393024568       21880  -393024592       21880\n",
      "  -393024616       21880  -393022648       21880  -393022672       21880\n",
      "  -393022696       21880  -393022720       21880  -393022744       21880\n",
      "  -393022768       21880  -393022792       21880  -393022816       21880\n",
      "  -393022840       21880  -393022864       21880  -393022888       21880\n",
      "  -393022912       21880  -393022936       21880  -393022960       21880\n",
      "  -393022984       21880  -393023008       21880  -393023032       21880\n",
      "  -393023056       21880  -393023080       21880  -393023104       21880\n",
      "  -393023128       21880  -393023152       21880  -393023176       21880\n",
      "  -393023200       21880  -393023224       21880  -393023248       21880\n",
      "  -393023272       21880  -393023296       21880  -393023320       21880\n",
      "  -393023344       21880  -393023368       21880  -393023392       21880\n",
      "  -393023416       21880  -393023440       21880  -393023464       21880\n",
      "  -393023488       21880  -393023512       21880  -393023536       21880\n",
      "  -393023560       21880  -393023584       21880  -393023608       21880\n",
      "  -393021640       21880  -393021664       21880  -393021688       21880\n",
      "  -393021712       21880  -393021736       21880  -393021760       21880\n",
      "  -393021784       21880  -393021808       21880  -393021832       21880\n",
      "  -393021856       21880  -393021880       21880  -393021904       21880\n",
      "  -393021928       21880  -393021952       21880  -393021976       21880\n",
      "  -393022000       21880  -393022024       21880  -393022048       21880\n",
      "  -393022072       21880  -393022096       21880  -393022120       21880\n",
      "  -393022144       21880  -393022168       21880  -393022192       21880\n",
      "  -393022216       21880  -393022240       21880  -393022264       21880\n",
      "  -393022288       21880  -393022312       21880  -393022336       21880\n",
      "  -393022360       21880  -393022384       21880  -393022408       21880\n",
      "  -393022432       21880  -393022456       21880  -393022480       21880\n",
      "  -393022504       21880  -393022528       21880  -393022552       21880\n",
      "  -393022576       21880  -393022600       21880  -393020632       21880\n",
      "  -393020656       21880  -393020680       21880  -393020704       21880\n",
      "  -393020728       21880  -393020752       21880  -393020776       21880\n",
      "  -393020800       21880  -393020824       21880  -393020848       21880\n",
      "  -393020872       21880  -393020896       21880  -393020920       21880\n",
      "  -393020944       21880  -393020968       21880  -393020992       21880\n",
      "  -393021016       21880  -393021040       21880  -393021064       21880\n",
      "  -393021088       21880  -393021112       21880  -393021136       21880\n",
      "  -393021160       21880  -393021184       21880  -393021208       21880\n",
      "  -393021232       21880  -393021256       21880  -393021280       21880\n",
      "  -393021304       21880  -393021328       21880  -393021352       21880\n",
      "  -393021376       21880  -393021400       21880  -393021424       21880\n",
      "  -393021448       21880  -393021472       21880  -393021496       21880\n",
      "  -393021520       21880  -393021544       21880  -393021568       21880\n",
      "  -422660016       21880  -422659992       21880  -422659968       21880\n",
      "  -422659944       21880  -422659920       21880  -422659896       21880\n",
      "  -422659872       21880  -422659848       21880  -422659824       21880\n",
      "  -422659800       21880  -422659776       21880  -422659752       21880\n",
      "  -422659728       21880  -422659704       21880  -422659680       21880\n",
      "  -422659656       21880  -422661624       21880  -422661600       21880\n",
      "  -422661576       21880  -422661552       21880  -422661528       21880\n",
      "  -422661504       21880  -422661480       21880  -422661456       21880\n",
      "  -422661432       21880  -422661408       21880  -422661384       21880\n",
      "  -422661360       21880  -422661336       21880  -422661312       21880]\n"
     ]
    }
   ],
   "source": [
    "# total ra\n",
    "label_train = np.ndarray(900, dtype=np.int32)\n",
    "label_train[0:300]=1 # for namo \n",
    "label_train[0:300]=1 # for ak\n",
    "label_train[0:300]=1 # for people\n",
    "\n",
    "# label_array_namo = np.full((400,1),1)\n",
    "# label_array_ak = np.full((400,1),2)\n",
    "# label_array_people = np.full((400,1),3)\n",
    "# # print label_array_ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  this is if i want to merge label in dataset individaul\n",
    "# final_dataset_namo = np.append(data_set_namo,label_array_namo,axis=1)\n",
    "# final_dataset_ak = np.append(data_set_ak,label_array_ak,axis=1)\n",
    "# final_dataset_people = np.append(data_set_people,label_array_people,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# total image in each image is = 400\n",
    "label_array = np.ndarray(400*3, dtype=np.int32)\n",
    "# total image in each image is = 50\n",
    "label_array[0:400] = 1\n",
    "label_array[400:800] = 2\n",
    "label_array[800:1200] = 3\n",
    "# label_array_namo.fill(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def normalize(x):\n",
    "#     #using formulae = (x-x(min))/(x(max)-x(min))\n",
    "#     x_min = np.min(x)\n",
    "#     x_max = np.max(x)\n",
    "#     x_final_normalised = list()\n",
    "# #     print \"xmin \", x_min\n",
    "# #     print \"xmax \", x_max\n",
    "    \n",
    "#     for i in x:\n",
    "# #         print i\n",
    "#         x_final_normalised.append((i-x_min)/(x_max-x_min))\n",
    "        \n",
    "#     return np.array(x_final_normalised)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# normalised_array = normalize(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def encode(x):\n",
    "#     y = np.zeros(3)\n",
    "#     np.put(y,x,1)\n",
    "#     return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def one_hot_encode(x):\n",
    "#     one_hot = list()\n",
    "    \n",
    "#     for i in x:\n",
    "#         one_hot.append(encode(i))\n",
    "#     return np.array(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# something to be done here, preprocess training,\n",
    "# valid, and testing set\n",
    "# preprossing includes, normalising, one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# leave it above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
